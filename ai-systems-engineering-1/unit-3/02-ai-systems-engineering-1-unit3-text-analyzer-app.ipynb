{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "<div align=\"center\">\n<img src=\"https://poorit.in/image.png\" alt=\"Poorit\" width=\"40\" style=\"vertical-align: middle;\"> <b>AI SYSTEMS ENGINEERING 1</b>\n\n## Unit 3: Build a Text Analyzer App\n\n**CV Raman Global University, Bhubaneswar**  \n*AI Center of Excellence*\n\n---\n\n</div>\n\n---\n\n### What You'll Learn\n\nIn this notebook, you will:\n\n1. **Understand local models vs APIs** — free, private, no API keys needed\n2. **Use new HuggingFace pipelines** — named entity recognition and zero-shot classification\n3. **Build flexible UIs with `gr.Blocks`** — rows, columns, and tabs\n4. **Create a multi-tool text analyzer app** with Gradio\n\n**Prerequisites:** Notebook 01 (HuggingFace Pipelines & Tokenization), Unit 2 Gradio basics\n\n---"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers torch gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gradio as gr\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "print(f\"Using: {'GPU' if device == 0 else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Local Models vs APIs\n",
    "\n",
    "In Unit 2, we built Gradio apps powered by **API-based models** (OpenAI, Gemini). In this notebook, we'll use **local HuggingFace models** instead.\n",
    "\n",
    "| | API Models (Unit 2) | Local Models (This Notebook) |\n",
    "|---|---|---|\n",
    "| **Cost** | Pay per token | Free |\n",
    "| **Setup** | Need API keys | No keys needed |\n",
    "| **Privacy** | Data sent to provider | Data stays on your machine |\n",
    "| **Capability** | Very powerful (GPT-4, Gemini) | Smaller, task-specific |\n",
    "| **Speed** | Fast (provider hardware) | Depends on your hardware |\n",
    "\n",
    "**Key insight:** Local models are great for well-defined tasks (classification, NER, summarization) where you don't need a massive general-purpose model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Loading Our Pipelines\n",
    "\n",
    "We'll load three pipelines for our text analyzer app. You already used `sentiment-analysis` in Notebook 01 — now let's add two more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n",
    "\n",
    "Classifies text as positive or negative. Same pipeline from Notebook 01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pipeline(\"sentiment-analysis\", device=device)\n",
    "\n",
    "result = sentiment(\"I really enjoyed this course on AI!\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "### Named Entity Recognition (NER)\n",
    "\n",
    "Identifies entities in text — people, organizations, locations, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": "ner = pipeline(\"ner\", aggregation_strategy=\"simple\", device=device)\n\nresult = ner(\"Sundar Pichai is the CEO of Google, headquartered in Mountain View, California.\")\n\nfor entity in result:\n    print(f\"{entity['word']:20s} → {entity['entity_group']} (confidence: {entity['score']:.2f})\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": "### Zero-Shot Classification\n\nClassifies text into categories **you define at runtime** — no retraining needed. The model decides which label fits best."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": "classifier = pipeline(\"zero-shot-classification\", device=device)\n\ntext = \"The stock market rallied today after the Federal Reserve announced lower interest rates.\"\nlabels = [\"politics\", \"sports\", \"finance\", \"technology\", \"health\"]\n\nresult = classifier(text, candidate_labels=labels)\n\nfor label, score in zip(result[\"labels\"], result[\"scores\"]):\n    print(f\"  {label:12s} → {score:.2f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "We'll also reuse the **GPT-2 tokenizer** from Notebook 01 for a token counting feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "text = \"Hello, I am studying AI at CV Raman University!\"\n",
    "tokens = tokenizer.encode(text)\n",
    "print(f\"Text: {text}\")\n",
    "print(f\"Token count: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Quick Recap — `gr.Interface`\n",
    "\n",
    "In Unit 2, you learned the basic Gradio pattern:\n",
    "\n",
    "```python\n",
    "gr.Interface(fn=your_function, inputs=\"textbox\", outputs=\"textbox\").launch()\n",
    "```\n",
    "\n",
    "Let's wrap our sentiment pipeline in `gr.Interface` — same pattern as Unit 2, but now with a **local model** instead of an API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(text):\n",
    "    result = sentiment(text)[0]\n",
    "    return f\"{result['label']} (confidence: {result['score']:.2f})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.Interface(\n",
    "    fn=analyze_sentiment,\n",
    "    inputs=gr.Textbox(label=\"Enter text:\", lines=3),\n",
    "    outputs=gr.Textbox(label=\"Sentiment:\"),\n",
    "    title=\"Sentiment Analyzer\",\n",
    "    flagging_mode=\"never\"\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "This works, but `gr.Interface` gives you a fixed layout. What if we want more control — side-by-side panels, tabs, or multiple tools in one app?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Introducing `gr.Blocks`\n",
    "\n",
    "`gr.Blocks` gives you full control over layout. Instead of the fixed input → output structure of `gr.Interface`, you can arrange components however you want.\n",
    "\n",
    "| Feature | `gr.Interface` | `gr.Blocks` |\n",
    "|---|---|---|\n",
    "| Layout | Fixed (inputs → outputs) | Fully customizable |\n",
    "| Complexity | Simple, one function | Multiple functions, interactions |\n",
    "| Use case | Quick demos | Full applications |\n",
    "\n",
    "### Side-by-Side Layout with `gr.Row`\n",
    "\n",
    "Let's rebuild the sentiment analyzer with a side-by-side layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Sentiment Analyzer\")\n",
    "\n",
    "    with gr.Row():\n",
    "        text_input = gr.Textbox(label=\"Enter text:\", lines=3)\n",
    "        result_output = gr.Textbox(label=\"Sentiment:\")\n",
    "\n",
    "    btn = gr.Button(\"Analyze\")\n",
    "    btn.click(fn=analyze_sentiment, inputs=text_input, outputs=result_output)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "Key differences from `gr.Interface`:\n",
    "\n",
    "- **`gr.Row()`** places components side by side\n",
    "- **`gr.Button()`** gives explicit submit control\n",
    "- **`.click()`** connects the button to the function\n",
    "- You choose where each component goes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Build the Text Analyzer App\n",
    "\n",
    "Now let's combine all our pipelines into a single multi-tool app using **`gr.Tab`**. We'll build it incrementally — one tab at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "### Step 1: Define the functions\n",
    "\n",
    "Each tab needs a function. Let's define them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": "def analyze_sentiment(text):\n    \"\"\"Return sentiment label and confidence.\"\"\"\n    result = sentiment(text)[0]\n    return f\"{result['label']} (confidence: {result['score']:.2f})\"\n\n\ndef extract_entities(text):\n    \"\"\"Return named entities as formatted text.\"\"\"\n    results = ner(text)\n    if not results:\n        return \"No entities found.\"\n\n    output = \"\"\n    for entity in results:\n        output += f\"**{entity['word']}** → {entity['entity_group']} ({entity['score']:.2f})\\n\\n\"\n    return output\n\n\ndef classify_text(text, labels):\n    \"\"\"Classify text into user-defined categories.\"\"\"\n    label_list = [l.strip() for l in labels.split(\",\") if l.strip()]\n    if not label_list:\n        return \"Please enter at least one label (comma-separated).\"\n    result = classifier(text, candidate_labels=label_list)\n\n    output = \"\"\n    for label, score in zip(result[\"labels\"], result[\"scores\"]):\n        bar = \"█\" * int(score * 20)\n        output += f\"**{label}:** {score:.2f} {bar}\\n\\n\"\n    return output\n\n\ndef count_tokens(text):\n    \"\"\"Return token count and breakdown.\"\"\"\n    tokens = tokenizer.encode(text)\n    token_strings = tokenizer.convert_ids_to_tokens(tokens)\n\n    output = f\"**Total tokens:** {len(tokens)}\\n\\n\"\n    output += f\"**Characters per token:** {len(text)/len(tokens):.1f}\\n\\n\"\n    output += \"**Token breakdown:**\\n\\n\"\n    for tid, ts in zip(tokens, token_strings):\n        output += f\"- `{ts}` (ID: {tid})\\n\"\n    return output"
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "### Step 2: Build the app with tabs\n",
    "\n",
    "We use `gr.Tab` inside `gr.Blocks` to create a tabbed interface. Each tab is its own mini-app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": "with gr.Blocks() as app:\n    gr.Markdown(\"# Text Analyzer\")\n    gr.Markdown(\"Analyze text using local AI models — no API keys needed.\")\n\n    with gr.Tab(\"Sentiment\"):\n        sent_input = gr.Textbox(label=\"Enter text:\", lines=3)\n        sent_output = gr.Textbox(label=\"Result:\")\n        sent_btn = gr.Button(\"Analyze Sentiment\")\n        sent_btn.click(fn=analyze_sentiment, inputs=sent_input, outputs=sent_output)\n\n    with gr.Tab(\"Named Entities\"):\n        ner_input = gr.Textbox(label=\"Enter text:\", lines=3)\n        ner_output = gr.Markdown(label=\"Entities:\")\n        ner_btn = gr.Button(\"Extract Entities\")\n        ner_btn.click(fn=extract_entities, inputs=ner_input, outputs=ner_output)\n\n    with gr.Tab(\"Classifier\"):\n        cls_input = gr.Textbox(label=\"Enter text:\", lines=3)\n        cls_labels = gr.Textbox(label=\"Categories (comma-separated):\", value=\"politics, sports, finance, technology, health\")\n        cls_output = gr.Markdown(label=\"Classification:\")\n        cls_btn = gr.Button(\"Classify\")\n        cls_btn.click(fn=classify_text, inputs=[cls_input, cls_labels], outputs=cls_output)\n\n    with gr.Tab(\"Token Counter\"):\n        tok_input = gr.Textbox(label=\"Enter text:\", lines=3)\n        tok_output = gr.Markdown(label=\"Token Info:\")\n        tok_btn = gr.Button(\"Count Tokens\")\n        tok_btn.click(fn=count_tokens, inputs=tok_input, outputs=tok_output)\n\napp.launch()"
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": "That's the full app — four NLP tools in one interface, all running locally. Try each tab with different inputs.\n\n**Sample texts to try:**\n\n- **Sentiment:** `\"This movie was absolutely brilliant, I loved every minute of it!\"`\n- **NER:** `\"Elon Musk founded SpaceX in Hawthorne, California in 2002.\"`\n- **Classifier:** `\"NASA launched a new telescope to study distant galaxies.\"` with labels `science, politics, sports, entertainment`\n- **Token Counter:** `\"Tokenization splits text into smaller pieces called tokens.\"`"
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Exercise\n",
    "\n",
    "**Add a 5th tab** to the text analyzer app. Choose one:\n",
    "\n",
    "- **Text Generation** — use `pipeline(\"text-generation\", model=\"gpt2\")` to complete a user's prompt\n",
    "- **Question Answering** — use `pipeline(\"question-answering\")` with a context + question input\n",
    "\n",
    "Starter code is provided below. Fill in the function and add your tab to the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Add a 5th tab\n",
    "\n",
    "# Step 1: Load your pipeline\n",
    "# generator = pipeline(\"text-generation\", model=\"gpt2\", device=device)\n",
    "\n",
    "\n",
    "# Step 2: Define the function\n",
    "def generate_text(prompt):\n",
    "    # Use the pipeline to generate text from the prompt\n",
    "    # Return the generated text\n",
    "    pass\n",
    "\n",
    "\n",
    "# Step 3: Build the full app with 5 tabs\n",
    "# Copy the app code from above and add your new tab\n",
    "\n",
    "# with gr.Blocks() as app:\n",
    "#     gr.Markdown(\"# Text Analyzer\")\n",
    "#     ... (keep the 4 existing tabs)\n",
    "#\n",
    "#     with gr.Tab(\"Text Generator\"):\n",
    "#         gen_input = gr.Textbox(label=\"Enter a prompt:\", lines=3)\n",
    "#         gen_output = gr.Textbox(label=\"Generated text:\", lines=5)\n",
    "#         gen_btn = gr.Button(\"Generate\")\n",
    "#         gen_btn.click(fn=generate_text, inputs=gen_input, outputs=gen_output)\n",
    "#\n",
    "# app.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": "---\n\n## 8. Key Takeaways\n\n1. **`gr.Blocks`** gives you full layout control — rows, columns, tabs\n\n2. **`gr.Tab`** lets you build multi-page apps in a single interface\n\n3. **HuggingFace pipelines** make it easy to add NLP features — sentiment, NER, classification, and more\n\n4. **Local models are free and private** — no API keys, no data leaving your machine\n\n5. **Same Gradio skills, different backend** — Unit 2 used APIs, this notebook used local models\n\n**Stretch goal:** Deploy your app to [HuggingFace Spaces](https://huggingface.co/spaces) for free hosting.\n\n---\n\n## Additional Resources\n\n- [Gradio Blocks Guide](https://www.gradio.app/guides/blocks-and-event-listeners)\n- [Gradio Tabbed Interfaces](https://www.gradio.app/guides/controlling-layout#tabs)\n- [HuggingFace Pipelines](https://huggingface.co/docs/transformers/pipeline_tutorial)\n- [HuggingFace Spaces](https://huggingface.co/spaces)\n\n---\n\n**Course Information:**\n- **Institution:** CV Raman Global University, Bhubaneswar\n- **Program:** AI Center of Excellence\n- **Course:** AI Systems Engineering 1\n- **Developed by:** [Poorit Technologies](https://poorit.in) — *Transform Graduates into Industry-Ready Professionals*\n\n---"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}