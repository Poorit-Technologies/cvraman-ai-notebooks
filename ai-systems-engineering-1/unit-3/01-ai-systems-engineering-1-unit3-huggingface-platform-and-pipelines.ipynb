{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://poorit.in/image.png\" alt=\"Poorit\" width=\"40\" style=\"vertical-align: middle;\"> <b>AI SYSTEMS ENGINEERING 1</b>\n",
    "\n",
    "## Unit 3: HuggingFace Platform and Pipelines\n",
    "\n",
    "**CV Raman Global University, Bhubaneswar**  \n",
    "*AI Center of Excellence*\n",
    "\n",
    "---\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### What You'll Learn\n",
    "\n",
    "In this notebook, you will:\n",
    "\n",
    "1. **Understand the HuggingFace ecosystem** — Hub, Transformers, Datasets\n",
    "2. **Use the Pipelines API** for quick inference without complex setup\n",
    "3. **Run text generation, sentiment analysis, and zero-shot classification**\n",
    "\n",
    "**Duration:** ~45 minutes\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# Check if GPU is available\n",
    "device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"Using CPU — pipelines will still work, just a bit slower.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. The HuggingFace Ecosystem\n",
    "\n",
    "HuggingFace is the largest platform for sharing and using AI models.\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| **Hub** | Repository of 500k+ models and datasets |\n",
    "| **Transformers** | Library for working with transformer models |\n",
    "| **Datasets** | Library for loading and processing datasets |\n",
    "| **Spaces** | Platform for hosting ML demos |\n",
    "\n",
    "The **Pipelines API** is the simplest way to use models — it handles tokenization, inference, and post-processing automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Text Generation Pipeline\n",
    "\n",
    "Let's start with text generation using GPT-2, a small but capable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a text generation pipeline\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Generate text from a prompt\nprompt = \"Artificial intelligence is transforming\"\n\nresult = generator(prompt, max_new_tokens=50, do_sample=True, temperature=0.7)\n\nprint(result[0][\"generated_text\"])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it — one line to load the model, one call to generate text. The pipeline handles tokenization, model inference, and decoding automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Sentiment Analysis Pipeline\n",
    "\n",
    "Sentiment analysis classifies text as positive or negative. The pipeline uses a pretrained model (DistilBERT fine-tuned on SST-2) by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sentiment analysis pipeline\n",
    "sentiment = pipeline(\"sentiment-analysis\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiment of multiple texts\n",
    "texts = [\n",
    "    \"I love this course! It's really helping me understand AI.\",\n",
    "    \"The weather today is terrible and I'm stuck indoors.\",\n",
    "    \"The food was okay, nothing special.\"\n",
    "]\n",
    "\n",
    "results = sentiment(texts)\n",
    "\n",
    "for text, result in zip(texts, results):\n",
    "    print(f\"Text: {text}\")\n",
    "    print(f\"Sentiment: {result['label']} (confidence: {result['score']:.2f})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Zero-Shot Classification\n",
    "\n",
    "Zero-shot classification can categorize text into labels it has **never been trained on**. You provide the labels at inference time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a zero-shot classifier\n",
    "classifier = pipeline(\"zero-shot-classification\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify a customer support ticket\n",
    "text = \"My order hasn't arrived yet and it's been 2 weeks. I need a refund.\"\n",
    "labels = [\"shipping issue\", \"payment problem\", \"product quality\", \"general inquiry\"]\n",
    "\n",
    "result = classifier(text, candidate_labels=labels)\n",
    "\n",
    "print(f\"Text: {text}\\n\")\n",
    "print(\"Classifications:\")\n",
    "for label, score in zip(result[\"labels\"], result[\"scores\"]):\n",
    "    print(f\"  {label}: {score:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the model correctly identifies this as a shipping issue — without ever being trained on these specific categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Exercise\n",
    "\n",
    "Try the pipelines yourself!\n",
    "\n",
    "**Step 1:** Run sentiment analysis on 3 sentences of your choice.  \n",
    "**Step 2:** Run zero-shot classification on a text with your own custom labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Sentiment analysis on your own sentences\n",
    "# Replace the strings below with your own text\n",
    "\n",
    "my_texts = [\n",
    "    # \"your first sentence here\",\n",
    "    # \"your second sentence here\",\n",
    "    # \"your third sentence here\",\n",
    "]\n",
    "\n",
    "results = sentiment(my_texts)\n",
    "\n",
    "for text, result in zip(my_texts, results):\n",
    "    print(f\"{text}\")\n",
    "    print(f\"  → {result['label']} ({result['score']:.2f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Zero-shot classification with your own text and labels\n",
    "# Replace the text and labels below\n",
    "\n",
    "my_text = \"\"  # your text here\n",
    "my_labels = []  # e.g. [\"sports\", \"politics\", \"technology\", \"entertainment\"]\n",
    "\n",
    "result = classifier(my_text, candidate_labels=my_labels)\n",
    "\n",
    "print(f\"Text: {my_text}\\n\")\n",
    "for label, score in zip(result[\"labels\"], result[\"scores\"]):\n",
    "    print(f\"  {label}: {score:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Pipelines abstract complexity** — tokenization, inference, and post-processing are handled automatically\n",
    "\n",
    "2. **Many tasks supported** — text generation, classification, summarization, QA, and more\n",
    "\n",
    "3. **Zero-shot classification is powerful** — classify text into any categories without training\n",
    "\n",
    "### Common Pipeline Tasks\n",
    "\n",
    "| Task | Pipeline Name | Example Model |\n",
    "|------|--------------|---------------|\n",
    "| Text Generation | `text-generation` | gpt2, llama |\n",
    "| Classification | `sentiment-analysis` | distilbert |\n",
    "| Zero-Shot | `zero-shot-classification` | bart-large-mnli |\n",
    "| Summarization | `summarization` | bart, t5 |\n",
    "| Question Answering | `question-answering` | roberta |\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In the next notebook, we'll explore how **tokenization** works under the hood — the process that converts text into numbers that models can understand.\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [HuggingFace Hub](https://huggingface.co/models)\n",
    "- [Transformers Documentation](https://huggingface.co/docs/transformers)\n",
    "- [Pipeline Tutorial](https://huggingface.co/docs/transformers/pipeline_tutorial)\n",
    "\n",
    "---\n",
    "\n",
    "**Course Information:**\n",
    "- **Institution:** CV Raman Global University, Bhubaneswar\n",
    "- **Program:** AI Center of Excellence\n",
    "- **Course:** AI Systems Engineering 1\n",
    "- **Developed by:** [Poorit Technologies](https://poorit.in) — *Transform Graduates into Industry-Ready Professionals*\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}