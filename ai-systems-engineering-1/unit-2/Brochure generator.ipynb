{
 "cells": [
  {
   "cell_type": "code",
   "id": "cell-0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q litellm gradio requests beautifulsoup4"
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "import gradio as gr\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from litellm import completion\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass(\"Enter your OpenAI API key: \")"
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "\n",
    "def fetch_website_contents(url):\n",
    "    \"\"\"\n",
    "    Return the title and contents of the website at the given url;\n",
    "    truncate to 2,000 characters as a sensible limit\n",
    "    \"\"\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    title = soup.title.string if soup.title else \"No title found\"\n",
    "    if soup.body:\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "    else:\n",
    "        text = \"\"\n",
    "    return (title + \"\\n\\n\" + text)[:2_000]"
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an assistant that analyzes the contents of a company website landing page\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits.\n",
    "Respond in markdown without code blocks.\n",
    "\"\"\""
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    yield \"\"\n",
    "    prompt = f\"Please generate a company brochure for {company_name}. Here is their landing page:\\n\"\n",
    "    prompt += fetch_website_contents(url)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    stream = completion(model=\"gpt-4o-mini\", messages=messages, stream=True)\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_input = gr.Textbox(label=\"Company name:\")\n",
    "url_input = gr.Textbox(label=\"Landing page URL including http:// or https://\")\n",
    "\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_brochure,\n",
    "    title=\"Brochure Generator\",\n",
    "    inputs=[name_input, url_input],\n",
    "    outputs=[message_output],\n",
    "    examples=[\n",
    "        [\"Hugging Face\", \"https://huggingface.co\"],\n",
    "        [\"Anthropic\", \"https://anthropic.com\"],\n",
    "    ],\n",
    "    flagging_mode=\"never\",\n",
    ")\n",
    "view.launch()"
   ],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
