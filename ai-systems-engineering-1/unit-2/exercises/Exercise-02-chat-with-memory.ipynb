{
 "nbformat": 4,
 "nbformat_minor": 4,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://poorit.in/image.png\" alt=\"Poorit\" width=\"40\" style=\"vertical-align: middle;\"> <b>AI SYSTEMS ENGINEERING 1</b>\n",
    "\n",
    "## Unit 2 Exercises: Chat with Memory\n",
    "\n",
    "**CV Raman Global University, Bhubaneswar**  \n",
    "*AI Center of Excellence*\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "Complete the exercises below using the setup provided. Exercises include both **fill-in-the-blank** and **coding** tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run the cells below to install packages and configure the API."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Install required packages\n",
    "!pip install -q openai gradio"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Configure OpenAI\n",
    "api_key = getpass(\"Enter your OpenAI API Key: \")\n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "client = OpenAI(api_key=api_key)\n",
    "MODEL = \"gpt-4o-mini\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q1: ChatInterface with History \u2014 Fill-in-the-Blank\n",
    "\n",
    "Create a chatbot that connects to GPT and includes conversation history. Fill in the blanks to:\n",
    "1. Convert the Gradio history format to OpenAI message format\n",
    "2. Build the full messages list with system prompt + history + current message\n",
    "3. Launch the ChatInterface\n",
    "\n",
    "**Reminder:** Gradio's `ChatInterface` with `type=\"messages\"` provides history as a list of dicts with `\"role\"` and `\"content\"` keys."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "system_message = \"You are a helpful assistant.\"\n",
    "\n",
    "def chat(message, history):\n",
    "    # Convert Gradio history format to OpenAI format\n",
    "    history = [{\"role\": h[\"___\"], \"content\": h[\"___\"]} for h in history]\n",
    "\n",
    "    # Build the messages list: system + history + current message\n",
    "    messages = (\n",
    "        [{\"role\": \"___\", \"content\": system_message}]\n",
    "        + ___\n",
    "        + [{\"role\": \"___\", \"content\": ___}]\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(model=MODEL, messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "gr.ChatInterface(fn=___, type=___).launch()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q2: Streaming in ChatInterface \u2014 Fill-in-the-Blank\n",
    "\n",
    "Add streaming to the chatbot so responses appear word-by-word. Fill in the blanks to:\n",
    "1. Enable streaming in the API call\n",
    "2. Extract content from each chunk\n",
    "3. Yield the accumulated response"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def chat(message, history):\n",
    "    # Convert history format\n",
    "    history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "\n",
    "    # Build messages\n",
    "    messages = (\n",
    "        [{\"role\": \"system\", \"content\": system_message}]\n",
    "        + history\n",
    "        + [{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "\n",
    "    # Stream the response\n",
    "    stream = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        ___=True  # Enable streaming\n",
    "    )\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].___.content or \"\"  # Extract from delta\n",
    "        ___ response  # Yield accumulated text\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written Response:** In 2\u20133 sentences, explain why conversation history is important for a chatbot and how it is passed to the API.\n",
    "\n",
    "**Your Answer:** *(Write 2-3 sentences)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q3: Custom System Prompt Chatbot \u2014 Implement the Function\n",
    "\n",
    "A system prompt and ChatInterface are set up below. Your task is to **implement the `chat` function body** that:\n",
    "1. Converts the Gradio history to OpenAI format\n",
    "2. Builds the messages list with the system prompt, history, and current message\n",
    "3. Calls the API and returns the response text\n",
    "\n",
    "**Hints:**\n",
    "- History items have `\"role\"` and `\"content\"` keys\n",
    "- The messages list should be: `[system message] + [history] + [current user message]`\n",
    "- Return `response.choices[0].message.content`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "system_message = \"\"\"\n",
    "You are a friendly travel guide for India. You help tourists plan trips,\n",
    "suggest destinations, provide cultural tips, and recommend local food.\n",
    "Always be enthusiastic and include practical tips like best time to visit.\n",
    "\"\"\"\n",
    "\n",
    "def chat(message, history):\n",
    "    \"\"\"Process a chat message with conversation history.\n",
    "\n",
    "    Args:\n",
    "        message: The user's current message\n",
    "        history: List of previous messages in Gradio format\n",
    "                 Each item has \"role\" and \"content\" keys\n",
    "\n",
    "    Returns:\n",
    "        The assistant's response text\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    pass\n",
    "\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q4: Airline Customer Support Chatbot \u2014 Build from Requirements\n",
    "\n",
    "Build a complete airline customer support chatbot with dynamic system prompts.\n",
    "\n",
    "### Requirements:\n",
    "1. **Define a base system prompt** for an Indian airline assistant that knows about:\n",
    "   - Flight routes (e.g., Delhi-Mumbai, Bangalore-Kolkata, Chennai-Hyderabad)\n",
    "   - Baggage policy (e.g., 15kg check-in, 7kg cabin for economy; 25kg check-in for business)\n",
    "   - General booking and travel information\n",
    "\n",
    "2. **Create dynamic system prompt logic** that adds extra context based on keywords in the user's message:\n",
    "   - If the message contains **\"baggage\"** or **\"luggage\"**: add detailed baggage policy (fees for extra kg, prohibited items, etc.)\n",
    "   - If the message contains **\"refund\"** or **\"cancel\"**: add refund/cancellation policy (24-hour free cancellation, fees after that, etc.)\n",
    "   - If the message contains **\"upgrade\"** or **\"business\"**: add premium services pitch (priority boarding, lounge access, extra baggage, etc.)\n",
    "\n",
    "3. **Write a streaming chat function** that uses the dynamic prompt selection\n",
    "\n",
    "4. **Build a ChatInterface** with a descriptive title and description\n",
    "\n",
    "### Available:\n",
    "- `client` \u2014 OpenAI client\n",
    "- `MODEL` \u2014 model name (`\"gpt-4o-mini\"`)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# YOUR CODE BELOW\n",
    "\n",
    "# Step 1: Define a base system prompt for the airline assistant\n",
    "base_system_message = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Step 2: Create the streaming chat function\n",
    "def chat(message, history):\n",
    "    \"\"\"Airline support chatbot with dynamic system prompts.\"\"\"\n",
    "    # 2a. Convert Gradio history to OpenAI format\n",
    "\n",
    "    # 2b. Start with the base system prompt\n",
    "\n",
    "    # 2c. Add extra context if message contains \"baggage\" or \"luggage\"\n",
    "\n",
    "    # 2d. Add extra context if message contains \"refund\" or \"cancel\"\n",
    "\n",
    "    # 2e. Add extra context if message contains \"upgrade\" or \"business\"\n",
    "\n",
    "    # 2f. Build the messages list (system + history + current message)\n",
    "\n",
    "    # 2g. Call the API with stream=True and yield results\n",
    "    pass\n",
    "\n",
    "\n",
    "# Step 3: Build the ChatInterface\n",
    "# 3a. Use gr.ChatInterface with fn, type, title, and description\n",
    "# 3b. Launch the interface\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written Response:** In 2\u20133 sentences, explain how dynamic system prompts improve the chatbot compared to using a single static system prompt.\n",
    "\n",
    "**Your Answer:** *(Write 2-3 sentences)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Course Information:**\n",
    "- **Institution:** CV Raman Global University, Bhubaneswar\n",
    "- **Program:** AI Center of Excellence\n",
    "- **Course:** AI Systems Engineering 1\n",
    "- **Developed by:** [Poorit Technologies](https://poorit.in) - *Transform Graduates into Industry-Ready Professionals*\n",
    "\n",
    "---"
   ]
  }
 ]
}