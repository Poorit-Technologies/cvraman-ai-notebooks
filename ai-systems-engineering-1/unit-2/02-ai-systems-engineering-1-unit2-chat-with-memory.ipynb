{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<div align=\"center\">\n<img src=\"https://poorit.in/image.png\" alt=\"Poorit\" width=\"40\" style=\"vertical-align: middle;\"> <b>AI SYSTEMS ENGINEERING 1</b>\n\n## Unit 2: Conversational AI with Memory\n\n**CV Raman Global University, Bhubaneswar**  \n*AI Center of Excellence*\n\n---\n\n[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Poorit-Technologies/cvraman-coe/blob/main/courses-contents/ai-systems-engineering-1/unit-2/02-ai-systems-engineering-1-unit2-chat-with-memory.ipynb)\n\n</div>\n\n---\n\n### What You'll Learn\n\nIn this notebook, you will:\n\n1. **Build a chatbot with conversation memory** using Gradio's ChatInterface\n2. **Understand how history is managed** in LLM conversations\n3. **Use system prompts for context** to customize chatbot behavior\n4. **Implement streaming chat responses** for better UX\n\n**Duration:** ~1 hour\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q openai gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI\n",
    "api_key = getpass(\"Enter your OpenAI API Key: \")\n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "client = OpenAI(api_key=api_key)\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Understanding ChatInterface\n",
    "\n",
    "Gradio's `ChatInterface` is specifically designed for chatbot UIs.\n",
    "\n",
    "It expects a callback function with this signature:\n",
    "```python\n",
    "def chat(message, history):\n",
    "    # message: the user's current message\n",
    "    # history: list of previous messages\n",
    "    return response\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple chatbot - just echoes\n",
    "def chat(message, history):\n",
    "    return f\"You said: {message}\"\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what history looks like\n",
    "def chat(message, history):\n",
    "    return f\"Message: {message}\\n\\nHistory: {history}\"\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Connecting to an LLM with Memory\n",
    "\n",
    "Now let's connect to a real LLM and include the conversation history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant.\"\n",
    "\n",
    "def chat(message, history):\n",
    "    # Convert Gradio history format to OpenAI format\n",
    "    history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "    \n",
    "    # Build the messages list\n",
    "    messages = (\n",
    "        [{\"role\": \"system\", \"content\": system_message}]\n",
    "        + history\n",
    "        + [{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "    \n",
    "    response = client.chat.completions.create(model=MODEL, messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Adding Streaming\n",
    "\n",
    "For a better user experience, let's stream the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    # Convert history format\n",
    "    history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "    \n",
    "    # Build messages\n",
    "    messages = (\n",
    "        [{\"role\": \"system\", \"content\": system_message}]\n",
    "        + history\n",
    "        + [{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "    \n",
    "    # Stream the response\n",
    "    stream = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        yield response\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Customizing Behavior with System Prompts\n",
    "\n",
    "System prompts allow you to customize the chatbot's personality and behavior.\n",
    "\n",
    "Let's create a shopping assistant for a clothing store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a helpful assistant in a clothing store called FashionHub.\n",
    "You should gently encourage customers to try items that are on sale.\n",
    "Kurtas are 60% off, and most other items are 50% off.\n",
    "\n",
    "For example, if a customer says 'I'm looking for traditional wear',\n",
    "you could reply: 'Wonderful! We have beautiful kurtas that are part of our sale - 60% off!'\n",
    "\n",
    "Be friendly and helpful. Keep responses concise.\n",
    "\"\"\"\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add more context\n",
    "system_message += \"\"\"\n",
    "If the customer asks for shoes, mention that shoes are not on sale today,\n",
    "but suggest they check out our kurtas and other traditional wear!\n",
    "\"\"\"\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Dynamic System Prompts\n",
    "\n",
    "We can modify the system prompt based on the user's message for more context-aware responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_system_message = \"\"\"\n",
    "You are a helpful assistant in a clothing store called FashionHub.\n",
    "You should gently encourage customers to try items that are on sale.\n",
    "Kurtas are 60% off, and most other items are 50% off.\n",
    "Be friendly and helpful. Keep responses concise.\n",
    "\"\"\"\n",
    "\n",
    "def chat(message, history):\n",
    "    # Convert history format\n",
    "    history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "    \n",
    "    # Dynamic system prompt based on message content\n",
    "    current_system = base_system_message\n",
    "    \n",
    "    if \"belt\" in message.lower():\n",
    "        current_system += \" The store does not sell belts. Suggest kurtas or other items instead.\"\n",
    "    \n",
    "    if \"return\" in message.lower() or \"refund\" in message.lower():\n",
    "        current_system += \" For returns/refunds, direct customers to visit the customer service desk with their receipt.\"\n",
    "    \n",
    "    # Build messages\n",
    "    messages = (\n",
    "        [{\"role\": \"system\", \"content\": current_system}]\n",
    "        + history\n",
    "        + [{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "    \n",
    "    # Stream response\n",
    "    stream = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        yield response\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Exercise: Build a Customer Support Chatbot\n",
    "\n",
    "Create a chatbot for an Indian airline that:\n",
    "1. Answers questions about flights and bookings\n",
    "2. Provides information about baggage policies\n",
    "3. Suggests premium services when appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Create an airline customer support chatbot\n",
    "# Define a system prompt with relevant context\n",
    "# Implement the chat function with streaming\n",
    "\n",
    "# Your implementation here\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **ChatInterface simplifies chatbot UIs** - handles history automatically\n",
    "\n",
    "2. **History management is crucial** - convert formats between Gradio and OpenAI\n",
    "\n",
    "3. **System prompts define behavior** - use them for personality, context, and rules\n",
    "\n",
    "4. **Dynamic prompts add flexibility** - modify system messages based on context\n",
    "\n",
    "### Message Structure Recap\n",
    "\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are...\"},\n",
    "    {\"role\": \"user\", \"content\": \"First user message\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"First response\"},\n",
    "    {\"role\": \"user\", \"content\": \"Second user message\"},\n",
    "    # ... and so on\n",
    "]\n",
    "```\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In the next notebook, we'll explore:\n",
    "- Tool calling (function calling)\n",
    "- Giving LLMs the ability to execute actions\n",
    "- Database integration\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [Gradio ChatInterface](https://www.gradio.app/docs/chatinterface)\n",
    "- [OpenAI Chat Completions](https://platform.openai.com/docs/guides/text-generation)\n",
    "\n",
    "---\n",
    "\n",
    "**Course Information:**\n",
    "- **Institution:** CV Raman Global University, Bhubaneswar\n",
    "- **Program:** AI Center of Excellence\n",
    "- **Course:** AI Systems Engineering 1\n",
    "- **Developed by:** [Poorit Technologies](https://poorit.in) - *Transform Graduates into Industry-Ready Professionals*\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}