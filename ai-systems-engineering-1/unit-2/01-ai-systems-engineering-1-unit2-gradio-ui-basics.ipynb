{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<div align=\"center\">\n<img src=\"https://poorit.in/image.png\" alt=\"Poorit\" width=\"40\" style=\"vertical-align: middle;\"> <b>AI SYSTEMS ENGINEERING 1</b>\n\n## Unit 2: Building User Interfaces with Gradio\n\n**CV Raman Global University, Bhubaneswar**  \n*AI Center of Excellence*\n\n</div>\n\n---\n\n### What You'll Learn\n\nIn this notebook, you will:\n\n1. **Build user interfaces with Gradio** - the simplest way to create ML demos\n2. **Create streaming LLM interfaces** for better user experience\n3. **Add model selection dropdowns** to switch between providers\n4. **Build a company pamphlet generator UI** as a practical project\n\n**Duration:** ~1.5 hours\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q openai gradio requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure API keys\n",
    "openai_api_key = getpass(\"Enter your OpenAI API Key: \")\n",
    "os.environ['OPENAI_API_KEY'] = openai_api_key\n",
    "\n",
    "# Optional: Google API key for Gemini\n",
    "google_api_key = getpass(\"Enter your Google API Key (or press Enter to skip): \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize clients\n",
    "openai_client = OpenAI(api_key=openai_api_key)\n",
    "\n",
    "GEMINI_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "gemini_client = OpenAI(api_key=google_api_key, base_url=GEMINI_URL) if google_api_key else None\n",
    "\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Your First Gradio Interface\n",
    "\n",
    "Gradio makes it incredibly simple to create web UIs for Python functions.\n",
    "\n",
    "The basic pattern is:\n",
    "```python\n",
    "gr.Interface(fn=your_function, inputs=\"textbox\", outputs=\"textbox\").launch()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple function to demonstrate\n",
    "def shout(text):\n",
    "    return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Gradio interface\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Connecting to an LLM\n",
    "\n",
    "Let's wrap our LLM call in a function and connect it to Gradio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant that responds in markdown.\"\n",
    "\n",
    "def message_gpt(prompt):\n",
    "    \"\"\"Send a message to GPT and return the response.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    response = openai_client.chat.completions.create(model=MODEL, messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a more polished interface\n",
    "message_input = gr.Textbox(label=\"Your message:\", lines=5)\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    title=\"GPT Assistant\",\n",
    "    inputs=[message_input],\n",
    "    outputs=[message_output],\n",
    "    examples=[\n",
    "        \"Explain machine learning in simple terms\",\n",
    "        \"What is the capital of India?\"\n",
    "    ],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Streaming Responses\n",
    "\n",
    "Streaming shows the response as it's generated, providing a much better user experience.\n",
    "\n",
    "We use Python **generators** (the `yield` keyword) for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gpt(prompt):\n",
    "    \"\"\"Stream a response from GPT.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    stream = openai_client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streaming interface\n",
    "message_input = gr.Textbox(label=\"Your message:\", lines=5)\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_gpt,\n",
    "    title=\"GPT Assistant (Streaming)\",\n",
    "    inputs=[message_input],\n",
    "    outputs=[message_output],\n",
    "    examples=[\n",
    "        \"Explain the Transformer architecture to a beginner\",\n",
    "        \"Write a short poem about coding\"\n",
    "    ],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Model Selection Dropdown\n",
    "\n",
    "Let's add the ability to choose between different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gemini(prompt):\n",
    "    \"\"\"Stream a response from Gemini.\"\"\"\n",
    "    if not gemini_client:\n",
    "        yield \"Gemini API key not configured.\"\n",
    "        return\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    stream = gemini_client.chat.completions.create(\n",
    "        model=\"gemini-1.5-flash\",\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_model(prompt, model):\n",
    "    \"\"\"Stream response from selected model.\"\"\"\n",
    "    if model == \"GPT\":\n",
    "        yield from stream_gpt(prompt)\n",
    "    elif model == \"Gemini\":\n",
    "        yield from stream_gemini(prompt)\n",
    "    else:\n",
    "        yield \"Unknown model selected.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interface with model selection\n",
    "message_input = gr.Textbox(label=\"Your message:\", lines=5)\n",
    "model_selector = gr.Dropdown([\"GPT\", \"Gemini\"], label=\"Select model\", value=\"GPT\")\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_model,\n",
    "    title=\"Multi-Model Assistant\",\n",
    "    inputs=[message_input, model_selector],\n",
    "    outputs=[message_output],\n",
    "    examples=[\n",
    "        [\"What is deep learning?\", \"GPT\"],\n",
    "        [\"Explain neural networks\", \"Gemini\"]\n",
    "    ],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 6. Project: Company Pamphlet Generator\n\nLet's build a practical application that scrapes a company website and generates a pamphlet."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping utility\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
    "}\n",
    "\n",
    "def fetch_website_contents(url, max_chars=2000):\n",
    "    \"\"\"Fetch and return the text content of a website.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url, headers=HEADERS, timeout=10)\n",
    "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "        \n",
    "        title = soup.title.string if soup.title else \"No title found\"\n",
    "        \n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "        else:\n",
    "            text = \"\"\n",
    "        \n",
    "        return (title + \"\\n\\n\" + text)[:max_chars]\n",
    "    except Exception as e:\n",
    "        return f\"Error fetching website: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Update system message for pamphlet generation\npamphlet_system = \"\"\"\nYou are an assistant that analyzes company website content\nand creates a short pamphlet for prospective customers, investors and recruits.\nRespond in markdown without code blocks.\n\"\"\"\n\ndef stream_pamphlet(company_name, url, model):\n    \"\"\"Generate a company pamphlet with streaming.\"\"\"\n    yield \"\"\n    \n    website_content = fetch_website_contents(url)\n    prompt = f\"Please generate a company pamphlet for {company_name}. Here is their landing page:\\n{website_content}\"\n    \n    messages = [\n        {\"role\": \"system\", \"content\": pamphlet_system},\n        {\"role\": \"user\", \"content\": prompt}\n    ]\n    \n    if model == \"GPT\":\n        client = openai_client\n        model_name = MODEL\n    else:\n        if not gemini_client:\n            yield \"Gemini API key not configured.\"\n            return\n        client = gemini_client\n        model_name = \"gemini-1.5-flash\"\n    \n    stream = client.chat.completions.create(\n        model=model_name,\n        messages=messages,\n        stream=True\n    )\n    \n    result = \"\"\n    for chunk in stream:\n        result += chunk.choices[0].delta.content or \"\"\n        yield result"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Pamphlet generator interface\nname_input = gr.Textbox(label=\"Company name:\")\nurl_input = gr.Textbox(label=\"Landing page URL (include https://):\")\nmodel_selector = gr.Dropdown([\"GPT\", \"Gemini\"], label=\"Select model\", value=\"GPT\")\npamphlet_output = gr.Markdown(label=\"Generated Pamphlet:\")\n\nview = gr.Interface(\n    fn=stream_pamphlet,\n    title=\"Company Pamphlet Generator\",\n    inputs=[name_input, url_input, model_selector],\n    outputs=[pamphlet_output],\n    examples=[\n        [\"Anthropic\", \"https://anthropic.com\", \"GPT\"],\n        [\"Hugging Face\", \"https://huggingface.co\", \"Gemini\"]\n    ],\n    flagging_mode=\"never\"\n)\nview.launch()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Exercise: Build a Product Description Generator\n",
    "\n",
    "Create a Gradio interface that takes a product URL and generates marketing copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Create a product description generator\n",
    "# 1. Define a system prompt for marketing copy\n",
    "# 2. Create a streaming function that fetches product page and generates description\n",
    "# 3. Build a Gradio interface\n",
    "\n",
    "# Your implementation here\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Gradio makes UI creation simple** - just wrap your function with `gr.Interface`\n",
    "\n",
    "2. **Streaming improves UX** - use generators (`yield`) for real-time output\n",
    "\n",
    "3. **Dropdowns add flexibility** - easily switch between models or options\n",
    "\n",
    "4. **Combine scraping + LLM** - powerful pattern for content generation\n",
    "\n",
    "### What's Next?\n",
    "\n",
    "In the next notebook, we'll explore:\n",
    "- Building conversational AI with memory\n",
    "- ChatInterface for chatbot UIs\n",
    "- System prompts for context\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [Gradio Documentation](https://www.gradio.app/guides/quickstart)\n",
    "- [Gradio Components](https://www.gradio.app/docs/components)\n",
    "\n",
    "---\n",
    "\n",
    "**Course Information:**\n",
    "- **Institution:** CV Raman Global University, Bhubaneswar\n",
    "- **Program:** AI Center of Excellence\n",
    "- **Course:** AI Systems Engineering 1\n",
    "- **Developed by:** [Poorit Technologies](https://poorit.in) - *Transform Graduates into Industry-Ready Professionals*\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}