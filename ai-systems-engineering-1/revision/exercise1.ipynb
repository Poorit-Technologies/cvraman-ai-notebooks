{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://poorit.in/image.png\" alt=\"Poorit\" width=\"40\" style=\"vertical-align: middle;\"> <b>AI SYSTEMS ENGINEERING 1</b>\n",
    "\n",
    "## Exercise: Write It From Scratch\n",
    "\n",
    "**CV Raman Global University, Bhubaneswar**  \n",
    "*AI Center of Excellence*\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Each code cell below contains **only comments** describing what to write. Your job is to write the actual code from memory — no peeking at previous notebooks!\n",
    "\n",
    "This covers the full Unit 1 + Unit 2 journey:\n",
    "\n",
    "| Cell | Topic |\n",
    "|------|-------|\n",
    "| 1 | Install libraries |\n",
    "| 2 | Import libraries |\n",
    "| 3 | Setup OpenAI API key |\n",
    "| 4 | Setup Gemini API key |\n",
    "| 5 | Create an OpenAI client |\n",
    "| 6 | Create a Gemini client |\n",
    "| 7 | Raw HTTP call to Gemini |\n",
    "| 8 | Messages list + API call |\n",
    "| 9 | Simple Gradio Interface |\n",
    "\n",
    "**Tip:** If you get stuck, think about the restaurant analogy — waiter, order slip, kitchen, bill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: Install Libraries\n",
    "# ============================================================\n",
    "# Install the following packages (use !pip install -q):\n",
    "#   - openai\n",
    "#   - tiktoken\n",
    "#   - requests\n",
    "#   - beautifulsoup4\n",
    "#   - gradio\n",
    "# ============================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: Import Libraries\n",
    "# ============================================================\n",
    "# Import the following:\n",
    "#   - os\n",
    "#   - json\n",
    "#   - getpass from getpass\n",
    "#   - OpenAI from openai\n",
    "#   - BeautifulSoup from bs4\n",
    "#   - requests\n",
    "#   - tiktoken\n",
    "#   - gradio as gr\n",
    "#   - Markdown and display from IPython.display\n",
    "# ============================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: Setup OpenAI API Key\n",
    "# ============================================================\n",
    "# 1. Use getpass to securely ask the user for their OpenAI key\n",
    "# 2. Store it in os.environ['OPENAI_API_KEY']\n",
    "# 3. Print a confirmation message\n",
    "# ============================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: Setup Gemini API Key\n",
    "# ============================================================\n",
    "# 1. Use getpass to securely ask the user for their Google key\n",
    "# 2. Store it in a variable (e.g. google_api_key)\n",
    "# 3. Set the Gemini base URL:\n",
    "#    https://generativelanguage.googleapis.com/v1beta/openai/\n",
    "# 4. Print a confirmation message\n",
    "# ============================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: Create an OpenAI Client\n",
    "# ============================================================\n",
    "# 1. Create an OpenAI client using your API key\n",
    "# 2. Set a MODEL variable (e.g. \"gpt-4o-mini\")\n",
    "# 3. Print which model you're using\n",
    "# ============================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: Create a Gemini Client\n",
    "# ============================================================\n",
    "# Create an OpenAI client that points to Gemini instead.\n",
    "# Hint: You use the same OpenAI() class, but pass in:\n",
    "#   - base_url = your Gemini base URL\n",
    "#   - api_key  = your Google API key\n",
    "# Print a confirmation message.\n",
    "# ============================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: Raw HTTP Call to the Gemini API\n",
    "# ============================================================\n",
    "# Instead of using the OpenAI client library, make a raw HTTP\n",
    "# call using requests.post().\n",
    "#\n",
    "# 1. Set up headers dict with:\n",
    "#    - \"Authorization\": \"Bearer <your_google_api_key>\"\n",
    "#    - \"Content-Type\": \"application/json\"\n",
    "#\n",
    "# 2. Set up payload dict with:\n",
    "#    - \"model\": \"gemini-2.0-flash\"\n",
    "#    - \"messages\": a list with one user message\n",
    "#\n",
    "# 3. Make the POST request to:\n",
    "#    <GEMINI_BASE_URL>chat/completions\n",
    "#    Pass headers=headers, json=payload\n",
    "#\n",
    "# 4. Print the response:\n",
    "#    response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "# ============================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 8: Messages List + API Call\n",
    "# ============================================================\n",
    "# 1. Create a messages list with:\n",
    "#    - A system message (role: \"system\") setting the\n",
    "#      assistant's behavior\n",
    "#    - A user message (role: \"user\") asking a question\n",
    "#\n",
    "# 2. Make an API call using client.chat.completions.create()\n",
    "#    Pass model and messages.\n",
    "#\n",
    "# 3. Print the response:\n",
    "#    response.choices[0].message.content\n",
    "# ============================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 9: Simple Gradio Interface\n",
    "# ============================================================\n",
    "# 1. Write a function that:\n",
    "#    - Takes a text prompt as input\n",
    "#    - Creates a messages list (system + user)\n",
    "#    - Calls the LLM using client.chat.completions.create()\n",
    "#    - Returns the response content\n",
    "#\n",
    "# 2. Create a gr.Interface with:\n",
    "#    - fn = your function\n",
    "#    - inputs = a textbox\n",
    "#    - outputs = a markdown component\n",
    "#    - flagging_mode = \"never\"\n",
    "#\n",
    "# 3. Call .launch() on the interface\n",
    "# ============================================================\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}