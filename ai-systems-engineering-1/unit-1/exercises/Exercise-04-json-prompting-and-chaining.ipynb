{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://poorit.in/image.png\" alt=\"Poorit\" width=\"40\" style=\"vertical-align: middle;\"> <b>AI SYSTEMS ENGINEERING 1</b>\n",
    "\n",
    "## Unit 1 Exercises: JSON Prompting, Chaining, and Streaming\n",
    "\n",
    "**CV Raman Global University, Bhubaneswar**  \n",
    "*AI Center of Excellence*\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "Complete the exercises below using the helper functions and setup provided. Each question has one or more empty code cells for your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run the cells below to install packages, import libraries, and define helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q openai requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Gemini API Key\n",
    "from google.colab import userdata\n",
    "from getpass import getpass\n",
    "\n",
    "GEMINI_API_KEY = getpass(\"Enter your Gemini API Key: \")\n",
    "\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=GEMINI_BASE_URL,\n",
    "    api_key=GEMINI_API_KEY\n",
    ")\n",
    "\n",
    "MODEL = \"gemini-2.0-flash\"\n",
    "print(f\"Gemini configured with model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for web scraping\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "\n",
    "def fetch_website_contents(url, max_chars=2000):\n",
    "    \"\"\"\n",
    "    Fetch and return the title and text content of a website.\n",
    "    Removes scripts, styles, and other non-text elements.\n",
    "    \"\"\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    title = soup.title.string if soup.title else \"No title found\"\n",
    "\n",
    "    if soup.body:\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "    else:\n",
    "        text = \"\"\n",
    "\n",
    "    return (title + \"\\n\\n\" + text)[:max_chars]\n",
    "\n",
    "\n",
    "def fetch_website_links(url):\n",
    "    \"\"\"\n",
    "    Return all links found on a webpage.\n",
    "    \"\"\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    links = [link.get(\"href\") for link in soup.find_all(\"a\")]\n",
    "    return [link for link in links if link]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q1: JSON Structured Output\n",
    "\n",
    "Ask the model to analyze the topic **\"Artificial Intelligence\"** and return a JSON response with the following keys:\n",
    "- `topic` — the topic name\n",
    "- `summary` — a 2-3 sentence summary\n",
    "- `key_concepts` — a list of 3-5 key concepts\n",
    "\n",
    "**Steps:**\n",
    "1. Write a system prompt that tells the model to respond in JSON with the keys above\n",
    "2. Call the API with `response_format` set to enable JSON mode\n",
    "3. Parse the JSON response and print it formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Write a system prompt that specifies the JSON keys\n",
    "system_prompt = \"\"\"\n",
    "___\n",
    "\"\"\"\n",
    "\n",
    "# Step 2: Call the API with JSON mode enabled\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": \"Analyze the topic: Artificial Intelligence\"}\n",
    "    ],\n",
    "    response_format={\"type\": \"___\"}  # What value enables JSON mode?\n",
    ")\n",
    "\n",
    "# Step 3: Parse the JSON response\n",
    "result = json.___(response.choices[0].message.content)  # Which json function parses a string?\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q2: One-Shot JSON Prompting for Link Classification\n",
    "\n",
    "Using the **one-shot prompting** pattern from the lecture, create a system prompt that includes an example JSON structure. Then use it to classify links from `https://anthropic.com` as relevant for a company pamphlet.\n",
    "\n",
    "**Steps:**\n",
    "1. Write a system prompt with an example JSON showing the expected output format\n",
    "2. Fetch links from the website and build the user prompt\n",
    "3. Call the API with JSON mode and display the selected links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: System prompt with one-shot JSON example\n",
    "LINK_SYSTEM_PROMPT = \"\"\"\n",
    "You are provided with a list of links found on a webpage.\n",
    "Decide which links would be most relevant for a company pamphlet,\n",
    "such as About page, Company page, or Careers/Jobs pages.\n",
    "Respond in JSON as in this example:\n",
    "\n",
    "___\n",
    "\"\"\"\n",
    "# Hint: The example JSON should have a \"links\" key containing a list of objects,\n",
    "# each with \"type\" and \"url\" keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build the user prompt with links from the website\n",
    "url = \"https://anthropic.com\"\n",
    "links = fetch_website_links(___)\n",
    "\n",
    "user_prompt = f\"\"\"\n",
    "Here is the list of links on the website {url} -\n",
    "Please decide which are relevant for a company pamphlet.\n",
    "Respond with the full https URL in JSON format.\n",
    "Do not include Terms of Service, Privacy, or email links.\n",
    "\n",
    "Links:\n",
    "\"\"\"\n",
    "user_prompt += \"\\n\".join(links[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Call the API with JSON mode\n",
    "response = client.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": ___},\n",
    "        {\"role\": \"user\", \"content\": ___}\n",
    "    ],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "selected_links = json.loads(response.choices[0].message.content)\n",
    "print(json.dumps(selected_links, indent=2))\n",
    "\n",
    "# Print just the URLs\n",
    "print(\"\\nSelected URLs:\")\n",
    "for link in selected_links.get(\"links\", []):\n",
    "    print(f\"  - [{link['type']}] {link['url']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q3: Chaining LLM Calls\n",
    "\n",
    "Build a **2-step pipeline** that chains LLM calls:\n",
    "1. **Step 1:** Use the link selection from Q2 to get relevant links\n",
    "2. **Step 2:** Fetch content from those links and generate a company pamphlet\n",
    "\n",
    "This demonstrates the **chaining pattern** — the output of one LLM call drives the input to the next.\n",
    "\n",
    "**Steps:**\n",
    "1. Complete `fetch_page_and_relevant_links()` to aggregate content from the main page and relevant links\n",
    "2. Write the pamphlet system prompt\n",
    "3. Complete `create_pamphlet()` to generate the final pamphlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_links(url):\n",
    "    \"\"\"Use LLM to select relevant links from a website (from Q2).\"\"\"\n",
    "    links = fetch_website_links(url)\n",
    "    user_prompt = f\"\"\"\n",
    "Here is the list of links on the website {url} -\n",
    "Please decide which are relevant for a company pamphlet.\n",
    "Respond with the full https URL in JSON format.\n",
    "Do not include Terms of Service, Privacy, or email links.\n",
    "\n",
    "Links:\n",
    "\"\"\"\n",
    "    user_prompt += \"\\n\".join(links[:50])\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": LINK_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    return json.loads(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Complete the function that chains Step 1 → Step 2\n",
    "def fetch_page_and_relevant_links(url):\n",
    "    \"\"\"Fetch main page and content from relevant links.\"\"\"\n",
    "    # Get the main page content\n",
    "    contents = fetch_website_contents(url)\n",
    "\n",
    "    # Use LLM to pick relevant links (this is the \"chain\")\n",
    "    relevant_links = ___(url)  # Which function from Q2 selects links?\n",
    "\n",
    "    # Combine everything into one string\n",
    "    result = f\"## Landing Page:\\n\\n{contents}\\n\\n## Relevant Links:\\n\"\n",
    "\n",
    "    for link in relevant_links.get('___', [])[:3]:  # What key holds the links list?\n",
    "        result += f\"\\n\\n### {link['type']}\\n\"\n",
    "        try:\n",
    "            result += fetch_website_contents(link[\"___\"])  # What key holds the URL?\n",
    "        except:\n",
    "            result += \"(Could not fetch content)\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Write the pamphlet system prompt\n",
    "PAMPHLET_SYSTEM_PROMPT = \"\"\"\n",
    "___\n",
    "\"\"\"\n",
    "# Hint: Tell the model to analyze company website content and create a professional\n",
    "# pamphlet in markdown. Include details about culture, products, and careers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Complete the pamphlet generation function\n",
    "def create_pamphlet(company_name, url):\n",
    "    \"\"\"Generate a company pamphlet using chained LLM calls.\"\"\"\n",
    "    # Build the user prompt with aggregated content\n",
    "    user_prompt = f\"\"\"\n",
    "You are looking at a company called: {company_name}\n",
    "Here are the contents of its landing page and other relevant pages.\n",
    "Use this information to build a short pamphlet in markdown.\n",
    "\n",
    "\"\"\"\n",
    "    user_prompt += ___(url)  # Which function aggregates page + relevant link content?\n",
    "    user_prompt = user_prompt[:5000]  # Truncate to fit context\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": ___},\n",
    "            {\"role\": \"user\", \"content\": ___}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it!\n",
    "pamphlet = create_pamphlet(\"Anthropic\", \"https://anthropic.com\")\n",
    "display(Markdown(pamphlet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Q4: Streaming Responses\n",
    "\n",
    "Convert the `create_pamphlet()` function into a **streaming** version that displays the response in real-time as it is generated.\n",
    "\n",
    "**Steps:**\n",
    "1. Enable streaming in the API call\n",
    "2. Loop through chunks and extract the content from each chunk\n",
    "3. Use `update_display()` to show the response as it builds up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_pamphlet(company_name, url):\n",
    "    \"\"\"Generate a pamphlet with streaming output.\"\"\"\n",
    "    user_prompt = f\"\"\"\n",
    "You are looking at a company called: {company_name}\n",
    "Here are the contents of its landing page and other relevant pages.\n",
    "Use this information to build a short pamphlet in markdown.\n",
    "\n",
    "\"\"\"\n",
    "    user_prompt += fetch_page_and_relevant_links(url)\n",
    "    user_prompt = user_prompt[:5000]\n",
    "\n",
    "    stream = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": PAMPHLET_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        ___=True  # What parameter enables streaming?\n",
    "    )\n",
    "\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "\n",
    "    for chunk in stream:\n",
    "        content = chunk.choices[0].___.content or ''  # How do you access content in a stream chunk?\n",
    "        response += content\n",
    "        ___(Markdown(response), display_id=display_handle.display_id)  # What function updates the display?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test streaming\n",
    "stream_pamphlet(\"Anthropic\", \"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written Response:** In 2\u20133 sentences, explain why chaining multiple LLM calls is considered an early form of Agentic AI.\n",
    "\n",
    "*Your answer here:*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Course Information:**\n",
    "- **Institution:** CV Raman Global University, Bhubaneswar\n",
    "- **Program:** AI Center of Excellence\n",
    "- **Course:** AI Systems Engineering 1\n",
    "- **Developed by:** [Poorit Technologies](https://poorit.in) - *Transform Graduates into Industry-Ready Professionals*\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}