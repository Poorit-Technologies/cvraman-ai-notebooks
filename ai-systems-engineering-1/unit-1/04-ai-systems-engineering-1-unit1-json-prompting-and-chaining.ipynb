{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "<div align=\"center\">\n<img src=\"https://poorit.in/image.png\" alt=\"Poorit\" width=\"40\" style=\"vertical-align: middle;\"> <b>AI SYSTEMS ENGINEERING 1</b>\n\n## Unit 1: JSON Prompting, Chaining, and Streaming\n\n**CV Raman Global University, Bhubaneswar**  \n*AI Center of Excellence*\n\n</div>\n\n---\n\n### What You'll Learn\n\nIn this notebook, you will:\n\n1. **Use JSON structured outputs** to get predictable responses from LLMs\n2. **Chain multiple LLM calls** to build complex workflows\n3. **Implement streaming responses** for better user experience\n4. **Build a company brochure generator** as a practical project\n\n**Duration:** ~2 hours\n\n---"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q openai requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from getpass import getpass\n",
    "from openai import OpenAI\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OpenAI\n",
    "api_key = getpass(\"Enter your OpenAI API Key: \")\n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "client = OpenAI(api_key=api_key)\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Web Scraping Utilities\n",
    "\n",
    "First, let's set up our web scraping functions (same as notebook 01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def fetch_website_contents(url, max_chars=2000):\n",
    "    \"\"\"Fetch and return the text content of a website.\"\"\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    title = soup.title.string if soup.title else \"No title found\"\n",
    "    \n",
    "    if soup.body:\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "    else:\n",
    "        text = \"\"\n",
    "    \n",
    "    return (title + \"\\n\\n\" + text)[:max_chars]\n",
    "\n",
    "\n",
    "def fetch_website_links(url):\n",
    "    \"\"\"Return all links found on a webpage.\"\"\"\n",
    "    response = requests.get(url, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    links = [link.get(\"href\") for link in soup.find_all(\"a\")]\n",
    "    return [link for link in links if link]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. JSON Structured Outputs\n",
    "\n",
    "When you need predictable, parseable responses from an LLM, use **JSON mode**.\n",
    "\n",
    "This is essential for:\n",
    "- Building pipelines where output feeds into code\n",
    "- Extracting structured data from text\n",
    "- Creating reliable automation\n",
    "\n",
    "### One-Shot Prompting\n",
    "\n",
    "We provide an example in the prompt to show the expected format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System prompt with JSON example (one-shot prompting)\n",
    "LINK_SYSTEM_PROMPT = \"\"\"\n",
    "You are provided with a list of links found on a webpage.\n",
    "Decide which links would be most relevant for a company brochure,\n",
    "such as About page, Company page, or Careers/Jobs pages.\n",
    "Respond in JSON as in this example:\n",
    "\n",
    "{\n",
    "    \"links\": [\n",
    "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
    "        {\"type\": \"careers page\", \"url\": \"https://another.full.url/careers\"}\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_links_prompt(url):\n",
    "    \"\"\"Create the user prompt for link selection.\"\"\"\n",
    "    links = fetch_website_links(url)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Here is the list of links on the website {url} -\n",
    "Please decide which are relevant for a company brochure.\n",
    "Respond with the full https URL in JSON format.\n",
    "Do not include Terms of Service, Privacy, or email links.\n",
    "\n",
    "Links:\n",
    "\"\"\"\n",
    "    prompt += \"\\n\".join(links[:50])  # Limit to first 50 links\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_relevant_links(url):\n",
    "    \"\"\"Use LLM to select relevant links from a website.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": LINK_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": create_links_prompt(url)}\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}  # Force JSON output\n",
    "    )\n",
    "    \n",
    "    result = response.choices[0].message.content\n",
    "    return json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test link selection\n",
    "links = select_relevant_links(\"https://anthropic.com\")\n",
    "print(json.dumps(links, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Chaining LLM Calls\n",
    "\n",
    "**Chaining** means using the output of one LLM call as input to another.\n",
    "\n",
    "This is an early example of **Agentic AI** patterns.\n",
    "\n",
    "### Our Pipeline:\n",
    "1. **Step 1**: Extract relevant links from website (using JSON output)\n",
    "2. **Step 2**: Fetch content from those links\n",
    "3. **Step 3**: Generate brochure from aggregated content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page_and_relevant_links(url):\n",
    "    \"\"\"Fetch main page and content from relevant links.\"\"\"\n",
    "    # Get main page content\n",
    "    contents = fetch_website_contents(url)\n",
    "    \n",
    "    # Get relevant links using LLM\n",
    "    relevant_links = select_relevant_links(url)\n",
    "    \n",
    "    # Aggregate content\n",
    "    result = f\"## Landing Page:\\n\\n{contents}\\n\\n## Relevant Links:\\n\"\n",
    "    \n",
    "    for link in relevant_links.get('links', [])[:3]:  # Limit to 3 links\n",
    "        result += f\"\\n\\n### {link['type']}\\n\"\n",
    "        try:\n",
    "            result += fetch_website_contents(link[\"url\"])\n",
    "        except:\n",
    "            result += \"(Could not fetch content)\"\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test content aggregation\n",
    "content = fetch_page_and_relevant_links(\"https://anthropic.com\")\n",
    "print(content[:1000] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Building the Brochure Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BROCHURE_SYSTEM_PROMPT = \"\"\"\n",
    "You are an assistant that analyzes company website content\n",
    "and creates a professional brochure for prospective customers, investors, and recruits.\n",
    "Respond in markdown without code blocks.\n",
    "Include details of company culture, products/services, and careers if available.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure_prompt(company_name, url):\n",
    "    \"\"\"Create the prompt for brochure generation.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "You are looking at a company called: {company_name}\n",
    "Here are the contents of its landing page and other relevant pages.\n",
    "Use this information to build a short brochure in markdown.\n",
    "\n",
    "\"\"\"\n",
    "    prompt += fetch_page_and_relevant_links(url)\n",
    "    return prompt[:5000]  # Truncate to fit context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_brochure(company_name, url):\n",
    "    \"\"\"Generate a company brochure.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": BROCHURE_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": create_brochure_prompt(company_name, url)}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a brochure\n",
    "brochure = create_brochure(\"Anthropic\", \"https://anthropic.com\")\n",
    "display(Markdown(brochure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Streaming Responses\n",
    "\n",
    "**Streaming** shows the response as it's generated, providing a better user experience.\n",
    "\n",
    "Instead of waiting for the complete response, you see text appear in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url):\n",
    "    \"\"\"Generate a brochure with streaming output.\"\"\"\n",
    "    stream = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": BROCHURE_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": create_brochure_prompt(company_name, url)}\n",
    "        ],\n",
    "        stream=True  # Enable streaming\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    \n",
    "    for chunk in stream:\n",
    "        content = chunk.choices[0].delta.content or ''\n",
    "        response += content\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test streaming\n",
    "stream_brochure(\"Anthropic\", \"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Changing Tone with System Prompts\n",
    "\n",
    "You can easily change the output style by modifying the system prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Humorous tone example\n",
    "HUMOROUS_SYSTEM_PROMPT = \"\"\"\n",
    "You are an assistant that creates witty, entertaining brochures about companies.\n",
    "Use humor and clever observations while still being informative.\n",
    "Respond in markdown without code blocks.\n",
    "\"\"\"\n",
    "\n",
    "def stream_humorous_brochure(company_name, url):\n",
    "    \"\"\"Generate a humorous brochure.\"\"\"\n",
    "    stream = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": HUMOROUS_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": create_brochure_prompt(company_name, url)}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    \n",
    "    for chunk in stream:\n",
    "        content = chunk.choices[0].delta.content or ''\n",
    "        response += content\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the humorous version\n",
    "# stream_humorous_brochure(\"Anthropic\", \"https://anthropic.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Exercise: Build a Product Description Generator\n",
    "\n",
    "Apply what you've learned to create a different application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Create a product description generator\n",
    "# that takes a product URL and generates marketing copy\n",
    "\n",
    "def generate_product_description(product_url):\n",
    "    \"\"\"\n",
    "    Generate marketing copy for a product page.\n",
    "    \n",
    "    Steps:\n",
    "    1. Fetch the product page content\n",
    "    2. Use LLM to generate compelling description\n",
    "    3. Return with streaming\n",
    "    \"\"\"\n",
    "    # Your implementation here\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **JSON mode** (`response_format={\"type\": \"json_object\"}`) ensures parseable outputs\n",
    "\n",
    "2. **One-shot prompting** - provide an example in the prompt for better formatting\n",
    "\n",
    "3. **Chaining LLM calls** creates powerful pipelines - output of one feeds into another\n",
    "\n",
    "4. **Streaming** (`stream=True`) provides better UX with real-time output\n",
    "\n",
    "5. **Tone control** - system prompts easily change the style of output\n",
    "\n",
    "### Pipeline Pattern\n",
    "\n",
    "```\n",
    "Input → LLM Call 1 (Extract/Analyze) → LLM Call 2 (Generate) → Output\n",
    "```\n",
    "\n",
    "This is an early form of **Agentic AI** - we'll explore this more in later units!\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- [OpenAI JSON Mode](https://platform.openai.com/docs/guides/structured-outputs)\n",
    "- [OpenAI Streaming](https://platform.openai.com/docs/api-reference/streaming)\n",
    "\n",
    "---\n",
    "\n",
    "**Course Information:**\n",
    "- **Institution:** CV Raman Global University, Bhubaneswar\n",
    "- **Program:** AI Center of Excellence\n",
    "- **Course:** AI Systems Engineering 1\n",
    "- **Developed by:** [Poorit Technologies](https://poorit.in) - *Transform Graduates into Industry-Ready Professionals*\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}